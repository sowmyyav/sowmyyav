{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_resp_deap.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOYCf0NTBXyvUwf8PWuNNJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sowmyyav/sowmyyav/blob/LSTM/lstm_resp_deap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-KFq1weljxz",
        "outputId": "a10a63e3-790a-4638-944f-f6d9d19c8170"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US61AYW5m1vB",
        "outputId": "d196cbb5-0ce2-4315-cce0-6ba7edea3496"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold\n",
        "import tensorflow as tf\n",
        "rsp_deap_data, rsp_deap_label = joblib.load(open('/content/drive/MyDrive/DEAP/data/lstm_slider128_rsp_16fs_64overlap_nobaseline.dat', 'rb'))\n",
        "\n",
        "#convert raw label into categorical data- this generates 10 classes\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def data_binarizer(ratings, threshold1, threshold2):\n",
        "\t\"\"\"binarizes the data below and above the threshold\"\"\"\n",
        "\tbinarized = []\n",
        "\tfor rating in ratings:\n",
        "\t\tif rating < threshold1:\n",
        "\t\t\tbinarized.append(0)\n",
        "\t\telif rating>= threshold2:\n",
        "\t\t\tbinarized.append(1)\n",
        "\treturn binarized\n",
        "\n",
        "#convert binarized label (0 and 1) into categorical data- this generates 2 classes\n",
        "y_valence = np.array(data_binarizer([el[0] for el in rsp_deap_label],5,5))\n",
        "Z1 = np.ravel(y_valence)\n",
        "y_train1 = to_categorical(Z1)\n",
        "y_train1\n",
        "#639ms/step - loss: 0.6824 - acc: 0.5666 - val_loss: 0.6833 - val_acc: 0.5676\n",
        "\n",
        "from collections import Counter\n",
        " # summarize observations by class labeL\n",
        "counter = Counter(y_valence)\n",
        "print(counter)\n",
        "\n",
        "#use stratify for split   \n",
        "X_train_rsp_val, X_test_rsp_val, y_train_rsp_val, y_test_rsp_val = train_test_split(rsp_deap_data, y_train1, test_size=0.2, random_state=42, stratify=y_train1)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "training_set_scaled = sc.fit_transform(X_train_rsp_val)\n",
        "testing_set_scaled = sc.transform(X_test_rsp_val)\n",
        "\n",
        "#sc.data_min_\n",
        "#sc.data_max_\n",
        "\n",
        "x_train = training_set_scaled.reshape(training_set_scaled.shape[0], 1, training_set_scaled.shape[1])\n",
        "x_test = testing_set_scaled.reshape(testing_set_scaled.shape[0],1, testing_set_scaled.shape[1])\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Permute\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Masking\n",
        "#from keras.utils import plot_model\n",
        "\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras import optimizers \n",
        "\n",
        "\n",
        "\n",
        "inputs = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
        "   \n",
        "input_shape = (1,x_train.shape[2])\n",
        "\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units = 256, return_sequences = True))  \n",
        "model.add(Dropout(0.3))     \n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))  \n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "    \n",
        "model.compile(optimizer =\"adam\", loss =keras.losses.categorical_crossentropy,metrics=[\"acc\"])\n",
        "model.summary()\n",
        "model.fit(x_train, y_train_rsp_val,epochs=10,batch_size=256,verbose=1,validation_data=(x_test, y_test_rsp_val))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 86880, 0: 66720})\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 16, 256)           133120    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 16, 256)           525312    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 16, 128)           197120    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 987,394\n",
            "Trainable params: 987,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 264s 537ms/step - loss: 0.6841 - acc: 0.5652 - val_loss: 0.6834 - val_acc: 0.5656\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 256s 533ms/step - loss: 0.6834 - acc: 0.5654 - val_loss: 0.6832 - val_acc: 0.5656\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 256s 534ms/step - loss: 0.6827 - acc: 0.5658 - val_loss: 0.6856 - val_acc: 0.5652\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 257s 535ms/step - loss: 0.6823 - acc: 0.5664 - val_loss: 0.6815 - val_acc: 0.5682\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 259s 540ms/step - loss: 0.6814 - acc: 0.5678 - val_loss: 0.6809 - val_acc: 0.5683\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 258s 537ms/step - loss: 0.6807 - acc: 0.5685 - val_loss: 0.6794 - val_acc: 0.5682\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 257s 535ms/step - loss: 0.6793 - acc: 0.5688 - val_loss: 0.6784 - val_acc: 0.5708\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 257s 536ms/step - loss: 0.6776 - acc: 0.5711 - val_loss: 0.6759 - val_acc: 0.5698\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 259s 539ms/step - loss: 0.6755 - acc: 0.5717 - val_loss: 0.6762 - val_acc: 0.5701\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 257s 535ms/step - loss: 0.6747 - acc: 0.5720 - val_loss: 0.6741 - val_acc: 0.5741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f142dde7290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gULIewDomvcy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}